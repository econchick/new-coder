<!DOCTYPE html>

<html>
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

<meta name="author" content="Lynn Root">
<meta name="description" content="Five Life Jackets to Throw to the New Coder - Python tutorials">
<meta name="generator" content="mynt v0.2.2">

<link rel="shortcut icon" href="/assets/images/favicon.ico" type="image/x-icon">



<link rel="stylesheet" href="/assets/css/screen3.css" type="text/css">
<link rel="stylesheet"href="/assets/css/css3-github-ribbon.css" type="text/css" />
<link rel="stylesheet" href="/assets/css/glyphicons.css" type="text/css">
<link href='http://fonts.googleapis.com/css?family=Yanone+Kaffeesatz:400,700,300,200' rel='stylesheet' type='text/css'>
<link rel="stylesheet" href="/assets/css/pygments2.css" type="text/css">
<script src="/assets/js/modernizr.js"></script>
<script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-39343031-1']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>
    
    <title>Part 4: Pipelining Data to Database &ndash; New Coder</title>
</head>

<body>
    <a href="https://github.com/econchick/new-coder" class="github-ribbon">Contribute on GitHub</a>
    <div id="container">
        <div id="nav">
            <ul>
                <li><a href="/">Home</a></li>
                <li><a href="/about/">About</a></li>
                <li><a href="/tutorials/">Tutorials</a></li>
                <li><a href="/Contact/">Contact</a></li>
            </ul>
            
        </div>
        
        <div id="header">
            <h1><a href="/">New C<span aria-hidden="true" class="icon" data-icon="&#xe308;">der</a></h1>
            <h2>five life jackets to throw to the new coder</h2>
        </div>

        <div id="content">
            
    <div class="item">
        <div class="header">
            <h2>Part 4: Pipelining Data to Database</h2>
        </div>
        
        <div class="body">
            <p>Pipelining our scraped data into our Postgres database.</p>
<h3 id="setup-our-pipeline">Setup our Pipeline</h3>
<p>We&#39;ve setup our spider to crawl and parse the HTML, and we&#39;ve set up our database to take the parse data. Now we have to connect the two together through a pipeline.</p>

<p>In <code>pipelines.py</code>, we will define a session (the actual connecting to the database), as well as the feeding/writing of data to the database.</p>

<p>We&#39;ll need to import SQLAlchemy&#39;s <code>sessionmaker</code> function to bind to the database (create that connection), as well as import our models.</p>
<div class="code"><div><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34</pre></div></td><td class="code"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">sqlalchemy.orm</span> <span class="kn">import</span> <span class="n">sessionmaker</span>
<span class="kn">from</span> <span class="nn">models</span> <span class="kn">import</span> <span class="n">Deals</span><span class="p">,</span> <span class="n">db_connect</span><span class="p">,</span> <span class="n">create_deals_table</span>


<span class="k">class</span> <span class="nc">LivingSocialPipeline</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Livingsocial pipeline for storing scraped items in the database&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initializes database connection and sessionmaker.</span>
<span class="sd">        Creates deals table.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">engine</span> <span class="o">=</span> <span class="n">db_connect</span><span class="p">()</span>
        <span class="n">create_deals_table</span><span class="p">(</span><span class="n">engine</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Session</span> <span class="o">=</span> <span class="n">sessionmaker</span><span class="p">(</span><span class="n">bind</span><span class="o">=</span><span class="n">engine</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">process_item</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">item</span><span class="p">,</span> <span class="n">spider</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Save deals in the database.</span>

<span class="sd">        This method is called for every item pipeline component.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">session</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span>
        <span class="n">deal</span> <span class="o">=</span> <span class="n">Deals</span><span class="p">(</span><span class="o">**</span><span class="n">item</span><span class="p">)</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="n">session</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">deal</span><span class="p">)</span>
            <span class="n">session</span><span class="o">.</span><span class="n">commit</span><span class="p">()</span>
        <span class="k">except</span><span class="p">:</span>
            <span class="n">session</span><span class="o">.</span><span class="n">rollback</span><span class="p">()</span>
            <span class="k">raise</span>
        <span class="k">finally</span><span class="p">:</span>
            <span class="n">session</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

        <span class="k">return</span> <span class="n">item</span>
</pre></div>
</td></tr></table></div></div>
<p>Here, we create a class, <code>LivingSocialPipeline()</code>.  We have a constructor function, <code>def __init__(self)</code> to initialize the class by defining the engine, the deals table, and binding/connecting to the database with the defined engine.</p>

<p>We then define <code>process_item()</code> that takes the parameters, <code>item</code> and <code>spider</code>. We establish a session with the database, then unpack an item (the data of one scraped deal) within our <code>Deal()</code> model.  We then add the <code>deal</code> to our database by calling <code>session.add()</code> – on this step, it’s not saved into the database - it’s still on SQLAlchemy level. Then, by calling <code>session.commit()</code>, it will put the into the database and the transaction will be committed.</p>

<p>However, if something went wrong during the <code>save()</code> and <code>commit()</code> portion of the database transaction, we will need to “undo” or <code>rollback()</code> the data that was committed since we do not want partial data in our database. The <code>commit()</code> and <code>rollback()</code> pair is meant to ensure that we have made <strong>all</strong> the changes or <strong>none</strong> if there was any sort of failure during the transaction.</p>

<p>In Python, we do this with a <code>try</code> and <code>except</code> clause. A <code>try</code> and <code>except</code> clause allows us to “catch” any errors if our desired operation fails.</p>

<p>We use the <code>finally</code> keyword to close the session – this basically means that whether or not we were successful in committing data, close the session/connection with the database.</p>
<h3 id="return-to-settings.py">Return to settings.py</h3>
<p>Nearly there – we need to add a variable to <code>settings.py</code> that tells scrapy where to find our pipeline when processing data.</p>

<p>So within <code>settings.py</code>, add another variable, <code>ITEM_PIPELINES</code>:</p>
<div class="code"><div><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="highlight"><pre><span class="n">ITEM_PIPELINES</span> <span class="o">=</span> <span class="p">[</span><span class="s">&#39;living_social.pipelines.LivingSocialPipeline&#39;</span><span class="p">]</span>
</pre></div>
</td></tr></table></div></div>
<p>This is the directory/module path to the pipeline we just defined.</p>

<p><a href="/Part-5-Running-our-scraper">Part 5 puts the project all together &rarr;</a></p>

        </div>
    </div>

        </div>
        
        <div id="footer">
            <p>Copyright &copy; 2013 Lynn Root &ndash; powered by <a href="http://mynt.mirroredwhite.com/">mynt</a></p>
        </div>
    </div>
</body>
</html>